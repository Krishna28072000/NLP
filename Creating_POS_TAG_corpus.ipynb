{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective : Performing POS(Parts of Speech) tagging on textual sequences**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code imports the nltk.data module, which is part of the Natural Language Toolkit (NLTK) library. This module allows access to various data resources (e.g., tokenizers, corpora) that NLTK uses. It enables loading and using pre-trained models or other resources for natural language processing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\gkris/nltk_data', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\\\nltk_data', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\\\share\\\\nltk_data', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\\\lib\\\\nltk_data', 'C:\\\\Users\\\\gkris\\\\AppData\\\\Roaming\\\\nltk_data', 'C:\\\\nltk_data', 'D:\\\\nltk_data', 'E:\\\\nltk_data']\n"
     ]
    }
   ],
   "source": [
    "print(nltk.data.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Corpus Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus.reader import TaggedCorpusReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code imports the `TaggedCorpusReader` class from the `nltk.corpus.reader` module, which is part of the NLTK library. This class is used to read and process tagged corpora, where each word is associated with a part-of-speech tag. It enables efficient access and manipulation of tagged linguistic data for tasks like part-of-speech tagging and syntactic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reader = TaggedCorpusReader('.', r'.*\\.pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method TaggedCorpusReader.words of <TaggedCorpusReader in 'e:\\\\NLP'>>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method TaggedCorpusReader.tagged_words of <TaggedCorpusReader in 'e:\\\\NLP'>>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.tagged_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Tokenize is the process in which sentence is splitted into chunks of words while handling punctuations and other language specific details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\gkris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'punkt_tab' tokenizer models are used for tokenizing text into sentences or words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\gkris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This resource is used for part-of-speech (POS) tagging, specifically the  tagger for English. It assigns grammatical categories like nouns, verbs, adjectives, etc., to words in a given text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing POS tagging on queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1 = word_tokenize(\"The Python lives in a very dense amazon forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('Python', 'NNP'),\n",
       " ('lives', 'VBZ'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('very', 'RB'),\n",
       " ('dense', 'JJ'),\n",
       " ('amazon', 'NN'),\n",
       " ('forest', 'NN')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lemmatization', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('more', 'RBR'),\n",
       " ('sophisticated', 'JJ'),\n",
       " ('approach', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('reducing', 'VBG'),\n",
       " ('words', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('their', 'PRP$'),\n",
       " ('base', 'NN'),\n",
       " ('form', 'NN'),\n",
       " ('(', '('),\n",
       " ('lemma', 'NN'),\n",
       " (')', ')'),\n",
       " (',', ','),\n",
       " ('where', 'WRB'),\n",
       " ('words', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('converted', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('their', 'PRP$'),\n",
       " ('correct', 'JJ'),\n",
       " ('dictionary', 'JJ'),\n",
       " ('form', 'NN'),\n",
       " ('by', 'IN'),\n",
       " ('considering', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('word', 'NN'),\n",
       " ('’', 'NNP'),\n",
       " ('s', 'NN'),\n",
       " ('meaning', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('context', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Unlike', 'IN'),\n",
       " ('stemming', 'VBG'),\n",
       " (',', ','),\n",
       " ('lemmatization', 'NN'),\n",
       " ('uses', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('vocabulary', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('morphological', 'JJ'),\n",
       " ('analysis', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('word', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = word_tokenize(\"Lemmatization is a more sophisticated approach to reducing words to their base form (lemma), where words are converted to their correct dictionary form by considering the word’s meaning and context. Unlike stemming, lemmatization uses a vocabulary and morphological analysis of the word.\")\n",
    "nltk.pos_tag(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pushpa', '$'),\n",
       " ('2', 'CD'),\n",
       " (':', ':'),\n",
       " ('The', 'DT'),\n",
       " ('Rule', 'NNP'),\n",
       " (',', ','),\n",
       " ('starring', 'VBG'),\n",
       " ('Allu', 'NNP'),\n",
       " ('Arjun', 'NNP'),\n",
       " (',', ','),\n",
       " ('has', 'VBZ'),\n",
       " ('made', 'VBN'),\n",
       " ('a', 'DT'),\n",
       " ('blazing', 'JJ'),\n",
       " ('start', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('North', 'JJ'),\n",
       " ('American', 'NNP'),\n",
       " ('box', 'NN'),\n",
       " ('office', 'NN'),\n",
       " (',', ','),\n",
       " ('surpassing', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('$', '$'),\n",
       " ('3', 'CD'),\n",
       " ('million', 'CD'),\n",
       " ('mark', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('its', 'PRP$'),\n",
       " ('premiere', 'NN'),\n",
       " ('shows', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('film', 'NN'),\n",
       " (',', ','),\n",
       " ('which', 'WDT'),\n",
       " ('had', 'VBD'),\n",
       " ('already', 'RB'),\n",
       " ('generated', 'VBN'),\n",
       " ('massive', 'JJ'),\n",
       " ('buzz', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('India', 'NNP'),\n",
       " (',', ','),\n",
       " ('is', 'VBZ'),\n",
       " ('now', 'RB'),\n",
       " ('challenging', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('records', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('biggest', 'JJS'),\n",
       " ('Indian', 'JJ'),\n",
       " ('films', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('region', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l3 = word_tokenize(\"Pushpa 2: The Rule, starring Allu Arjun, has made a blazing start at the North American box office, surpassing the $3 million mark with its premiere shows. The film, which had already generated massive buzz in India, is now challenging the records of the biggest Indian films in the region.\")\n",
    "nltk.pos_tag(l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'DT'),\n",
       " ('heavy', 'JJ'),\n",
       " ('crowd', 'NN'),\n",
       " ('rushed', 'VBN'),\n",
       " ('ahead', 'RB'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('woman', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('her', 'PRP$'),\n",
       " ('son', 'NN'),\n",
       " (',', ','),\n",
       " ('who', 'WP'),\n",
       " ('were', 'VBD'),\n",
       " ('trying', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('enter', 'VB'),\n",
       " ('inside', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('theatre', 'NN'),\n",
       " (',', ','),\n",
       " ('suffocated', 'VBN'),\n",
       " ('and', 'CC'),\n",
       " ('fell', 'VBD'),\n",
       " ('unconscious', 'JJ'),\n",
       " ('apparently', 'RB'),\n",
       " ('after', 'IN'),\n",
       " ('being', 'VBG'),\n",
       " ('pushed', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('crowd', 'NN'),\n",
       " (',', ','),\n",
       " ('police', 'NN'),\n",
       " ('said', 'VBD'),\n",
       " (',', ','),\n",
       " ('based', 'VBN'),\n",
       " ('on', 'IN'),\n",
       " ('preliminary', 'JJ'),\n",
       " ('investigation', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l4 = word_tokenize(\"A heavy crowd rushed ahead and the woman and her son, who were trying to enter inside the theatre, suffocated and fell unconscious apparently after being pushed by the crowd, police said, based on preliminary investigation.\")\n",
    "nltk.pos_tag(l4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('hostname', 'NN'),\n",
       " ('or', 'CC'),\n",
       " ('IP', 'NNP'),\n",
       " ('address', 'NN'),\n",
       " ('where', 'WRB'),\n",
       " ('the', 'DT'),\n",
       " ('MySQL', 'NNP'),\n",
       " ('server', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('located', 'VBN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l5 = word_tokenize(\"The hostname or IP address where the MySQL server is located.\")\n",
    "nltk.pos_tag(l5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
